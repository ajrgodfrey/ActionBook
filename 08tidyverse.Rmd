# BrailleR in the tidyverse {#Tidyverse}


Hadley wickham is unquestionably a superstar in the R community, and is perhaps the first R celebrity. There can't be room for too many people to have had a suite of packages collectively named after them by numerous users, but history will show that the "Hadleyverse" existed until Hadley himself renamed it the "tidyverse". The tidyverse owes its prominence to the relative simplicity it offers people doing what should be simple tasks, but haven't been as easy as might have been. According to the tidyverse package [@Rpkg-tidyverse] documentation, "The 'tidyverse' is a set of packages that work in harmony
    because they share common data representations and 'API' design." The package is just a simple way to make sure these packages are all installed and available to the user. Many users will not use all of the packages in the tidyverse, but among my favourites are `lubridate` [@Rpkg-lubridate] for handling dates in all manner of formats, `broom` [@Rpkg-broom] for handling linear models more efficient, 
`magrittr` [@Rpkg-magrittr] for giving me an alternative way of writing code, and of course `dplyr` [@Rpkg-dplyr] for making data manipulation and summarisation much easier to explain to others. The `ggplot2` package [@Rpkg-ggplot2] is another tidyverse package but it deserves a a separate chapter in order to show the way it works with `BrailleR`.  For the purposes of showing how `BrailleR` works with the tidyverse packages, or more accurately, the tidyverse way of working, the examples in this chapter all make use of the `dplyr` package and any tools it calls on to support its functionality.

To replicate the examples in this chapter, you will need to have the tidyverse packages installed before running the following commands that prepare them and `BrailleR` for use.

```{r GetLibraries}     
library(BrailleR)   
library(tidyverse)
```
## What is tidy and why do we care?

[@refWickham2014Tidy] describes tidy data as following three rules:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

and then says that data not following these rules as "messy" [@refWickham2014Tidy] .

We care because tidy data is ready for an analysis, while messy data needs to be made tidy. We care because it is easier to use tools designed for tidy data, and this all means we should get the desired results effectively and efficiently. We care because it is more common for data to be messy than tidy, and we must be able to take messy data and tidy it up.

To further quote [@refWickham2014Tidy] , the four most commonly used data manipulations (transformation, aggregation, filtering, and reordering) can be easily managed when we start with tidy data. The data manipulations are all performed by the `dplyr` package we use in this chapter. If we cannot work with tidy data successfully, then there is little hope for working with messy data. 

 
## What is the pipe operator, and why should we care?

The pipe operator `%>%`, found in the `magrittr` package,  is used throughout the tidyverse because it makes code simpler to read. A series of pipes is referred to as a pipe chain, and it is when there are multiple pipe commands issued in conjunction that its simplicity becomes increasingly obvious. 

Before the tidyverse, R users would follow a mixture of two general coding strategies. Either, we nested one command inside another, and perhaps another, and even worse, we'd nest and nest and so on; or, we can have each line of code have a single function, with the outcome of each function being stored as an explicitly named object. Nesting commands inside one another makes code very hard to read, as we read from the inside outwards to get a handle on what is actually being achieved. Storing each and every element of our working could have memory management implications, but is also prone to having too many named objects floating around that must be kept track of.

In contrast, a pipe chain can be written so that each function is applied in order, left to right, top to bottom, with the answer being stored in a named object at the end if we want, or quite commonly, just printed out for us. Whether you put the individual commands in a single line or with each pipe on its own line is a matter of style and personal preference.

A simple example using the `dplyr` package and the `airquality` data could ask for the coldest and hottest temperatures for each of the five months in this dataset.
```{r hottestDays}
airquality %>% group_by(Month) %>% summarise(ColdestDay = min(Temp), HottestDay = max(Temp))
```
 
In its most simple form, the outcome of everything done to the left of any pipe operator is used as the first argument of the first function to its right. This means that the first argument of the `group_by()` is the `airquality` data.frame we started with.  Note that there are ways to use the left-hand-side of the pipe operator as a second, third or so on, argument and even more adventurous ways of piping, but these are not relevant to the presentation of the `BrailleR` tools in this chapter.

The next important note about functions used in pipe chains is that the type of object coming out of the function is the same as the object that was pushed in, although it has probably been modified on its path through the function. For example, the `group_by()` function didn't drastically alter the `airquality` data.frame, but it did add information that has an impact at the next step in the pipe chain; without it, the `summarise()` command would have operated on the entire dataset as a whole without splitting the data into months before applying hte `min()` and `max()` functions.

The question is, how can we be sure that what is being passed on at each step is what we expected? In simple cases like that just seen, the answer justifies the work done to that point. Much longer pipe chains are possible, such as:





